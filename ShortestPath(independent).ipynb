{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "banned-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq, sys, copy, random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-pearl",
   "metadata": {},
   "source": [
    "# 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-chocolate",
   "metadata": {},
   "source": [
    "Thompson sampling의 다양한 적용 방법에 대한 설명을 하기 위해서는 Bernoulli Bandit보다는 복잡한 예시가 필요하다. 그래서 각 edge를 통과하는 데 걸리는 시간이 확률적으로 정해지는 Binary Bridge에서 최단 거리 탐색 문제를 Thompson sampling을 비롯한 여러 online learning algorithm들을 통해 해결하는 과정을 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-marine",
   "metadata": {},
   "source": [
    "## Binary Bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-estonia",
   "metadata": {},
   "source": [
    "Agent는 각 stage마다 한 edge를 타고 이동한다. $s$에서 출발해 $d$에 도착하기까지 총 $n$(짝수)개의 stage가 있다고 할 때, 책에서 설명하는 Binary Bridge는 아래와 같은 방식으로 정의되는 그래프다.\n",
    "\n",
    "1. (node 배치) $i=0,\\ldots,n$에 대해 아래 과정을 반복한다.\n",
    "    1. $p=(i + 1) - 2\\text{max}(0, i - \\frac{n}{2})$개의 노드를 정의한다.\n",
    "    1. $p$개의 node를 각각 $(i, j)$에 배치시킨다$(j=0,\\ldots,p-1)$\n",
    "1. (node 연결) 임의의 노드 $(x,y)$에 대해 아래 과정을 반복한다.\n",
    "    1. $(x+1, y+1)$이 정의되어 있으면 $(x,y)$에서 여기로 가는 방향을 가진 edge를 정의한다.\n",
    "    1. $(x+1, y)$이 정의되어 있으면 $(x,y)$에서 여기로 가는 방향을 가진 edge를 정의한다.\n",
    "    1. $(x+1, y)$로 가는 edge가 정의되어 있지 않고, $(x+1, y-1)$이 정의되어 있으면 $(x,y)$에서 여기로 가는 방향을 가진 edge를 정의한다.\n",
    "1. $(0,0), (n,0)$을 각각 $s, d$로 설정한다.\n",
    "\n",
    "간단히 말하면, 6개의 stage를 갖는 Binary Bridge의 형태는 책의 `Figure 4.2`와 같은 형태를 갖는다는 것이다. 참고로 책에서는 stage가 20개인 Binary Bridge를 생성해서 분석한다.\n",
    "\n",
    "<img src=\"images/binary_bridge.png\" alt=\"Binary Bridge example\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-shareware",
   "metadata": {},
   "source": [
    "## Stochastic Travel Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-authentication",
   "metadata": {},
   "source": [
    "edge를 통과하는 데 걸리는 시간이 확률적이라는 말은 어떤 edge든 통과하는 데 걸리는 시간이 매 step마다 다르다는 것이다. 마치 경부고속도로의 길이는 항상 일정한데, 서울에서 부산까지 가는 데 걸리는 시간은 매번 다른 것과 같다. 이런 특징을 갖는 모의 시스템을 구현하기 위해서, 인접한 두 노드 $m, n$을 연결하는 edge마다 $t$번째 step에서 그 edge를 지나는 데 걸리는 시간 $y_{m,n,t}$를 매번 다르게 생성하는 확률분포가 필요하다. 이 확률분포는\n",
    "- 기대값이 $\\theta_{m,n}$이고(즉, 이 edge를 지나는 데 걸리는 시간의 기대값은 $\\theta_{m,n}$)\n",
    "- 양의 실수에 대해 정의된 분포이어야 한다.\n",
    "\n",
    "책에서는 이를 아래와 같은 로그정규분포(Log Normal distribution)로 설정했다. $X$가 정규분포를 따르면 $Y=\\text{exp(X)}$는 로그정규분포를 따른다(즉, $\\ln Y$가 정규분포를 따름). 편의를 위해 아랫첨자를 모두 생략했다.\n",
    "$$\n",
    "y|\\theta\\sim LN(\\ln\\theta-\\frac{\\widetilde{\\sigma}^2}{2}, \\widetilde{\\sigma}^2),\\;\\;\\theta\\sim LN(\\mu_0,\\sigma^2_0)\n",
    "$$\n",
    "\n",
    "- $\\mathbb{E}[y|\\theta]=\\theta$가 될 수 있도록 하기 위해 $y$의 분포를 위와 같이 설정한 것이다(로그정규분포의 기대값 도출 증명은 하단의 appendix 참고). edge를 통과하는 데 걸리는 시간의 기대값인 $\\theta$역시 로그정규분포를 따르도록 해 양의 실수값만을 갖도록 한다.\n",
    "- 두 분포에 포함된 $(\\widetilde{\\sigma}^2, \\mu_0, \\sigma^2_0)$는 값이 알려져 있다고 가정하는 초모수들이다. 참고로 이 예시에서는 $\\widetilde{\\sigma}^2, \\mu_0, \\sigma^2_0=(1, -0.5, 1)$로 설정했다.\n",
    "\n",
    "여기까지의 내용을 통해 요약에서 언급한 `edge를 통과하는 데 걸리는 시간이 확률적으로 정해지는 Binary Bridge`를 정의했다. 이를 아래와 같이 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "insured-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryBridge:\n",
    "    \n",
    "    def __init__(self, n_stages, mu0, sig02):\n",
    "        \"\"\"\n",
    "        n_stages개의 stage를 갖고, 각 edge의 길이를 평균과 분산이 각각 mu0, sig02인 로그정규분포에서 생성하는 Binary Bridge를 생성하는 클래스\n",
    "        \"\"\"\n",
    "        assert (n_stages % 2 == 0), 'number of stages has to be even'\n",
    "        self.n = n_stages\n",
    "        self.mu0 = mu0\n",
    "        self.sig02 = sig02\n",
    "        \n",
    "        self.nodes = set()\n",
    "        self.graph = defaultdict(dict)\n",
    "        self.minimum_distance = None\n",
    "        self.shortest_path = None\n",
    "        \n",
    "        self._create_graph()\n",
    "        self._prev = defaultdict(list)\n",
    "        self._apply_dijkstra()\n",
    "        \n",
    "    def _get_stage_width(self, x):\n",
    "        \"\"\"\n",
    "        Binary Bridege가 정의되는 (x,y)평면에서 x축 위의 점마다 몇 개의 node가 있어야 하는지를 반환\n",
    "        \"\"\"\n",
    "        width = x - 2 * max(0, x - self.n/2) + 1\n",
    "        return int(width)\n",
    "    \n",
    "    def _generate_nodes(self):\n",
    "        \"\"\"\n",
    "        node들을 순서쌍 형태로 정의\n",
    "        \"\"\"\n",
    "        for x in range(self.n + 1):\n",
    "            for y in range(self._get_stage_width(x)):\n",
    "                self.nodes.add((x, y))\n",
    "        \n",
    "    def _generate_edges(self):\n",
    "        \"\"\"\n",
    "        정의된 node들을 기반으로 stage별 edge에 해당하는 theta를 로그정규분포에서 임의로 생성\n",
    "        \"\"\"\n",
    "        for x in range(self.n + 1):\n",
    "            for y in range(self._get_stage_width(x)):\n",
    "                current = (x, y)\n",
    "                up_shape = (x+1, y+1)\n",
    "                flat_shape = (x+1, y)\n",
    "                down_shape = (x+1, y-1)\n",
    "                \n",
    "                if up_shape in self.nodes:\n",
    "                    self.graph[current][up_shape] = np.exp(np.random.normal(self.mu0, np.sqrt(self.sig02)))\n",
    "                if flat_shape in self.nodes:\n",
    "                    self.graph[current][flat_shape] = np.exp(np.random.normal(self.mu0, np.sqrt(self.sig02)))\n",
    "                if down_shape in self.nodes and flat_shape not in self.nodes:\n",
    "                    self.graph[current][down_shape] = np.exp(np.random.normal(self.mu0, np.sqrt(self.sig02)))\n",
    "\n",
    "                \n",
    "    def _create_graph(self):\n",
    "        \"\"\"\n",
    "        위 method들을 기반으로 Binary Bridge를 생성\n",
    "        \"\"\"\n",
    "        self._generate_nodes()\n",
    "        self._generate_edges()\n",
    "        \n",
    "    def _apply_dijkstra(self):\n",
    "        \"\"\"\n",
    "        생성한 Binary Bridge에 대해 Dijkstra 알고리즘을 사용해 아래와 같은 정보들을 계산\n",
    "         - self.shortest_path    : s에서 d까지 가는 데 지나게 되는 edge에 대응하는 theta들의 총합이 가장 작은 경로\n",
    "         - self.minimum_distance : 위 경로에 대응하는 theta들의 총합\n",
    "        \"\"\"\n",
    "        distances = dict([(node, np.inf) for node in self.nodes])\n",
    "        distances[(0,0)] = 0\n",
    "        prev_path = defaultdict(list)\n",
    "\n",
    "        to_visit = [[0, (0,0)]]\n",
    "        while to_visit:\n",
    "            distance, visiting = heapq.heappop(to_visit)\n",
    "            for destination in self.graph[visiting].keys():\n",
    "                new_distance = distance + self.graph[visiting][destination]\n",
    "                if new_distance < distances[destination]:\n",
    "                    distances[destination] = new_distance\n",
    "                    prev_path[destination] = prev_path[visiting] + [visiting]\n",
    "                    heapq.heappush(to_visit, [new_distance, destination])\n",
    "        \n",
    "        arrival = (self.n, 0)\n",
    "        self.shortest_path = prev_path[arrival] + [arrival]\n",
    "        self.minimum_distance = distances[arrival]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-aluminum",
   "metadata": {},
   "source": [
    "이처럼 각 edge를 통과하는 데 걸리는 시간이 매번 다른 상황에서 최적의 경로를 결정할 때는, $s$에서 $d$로 가는 모든 경로를 여러번 시도해보며 알게 된 소요시간들을 바탕으로 각 edge별 통과 소요시간 기대값 $\\theta_{m,n}$에 대한 믿음을 업데이트해야 한다. 따라서 이 문제는 Thompson sampling을 비롯한 online learning algorithm들을 사용해서 해결할 수 있음을 알 수 있다. Experiment는 아래와 같은 step을 반복하며 진행된다.\n",
    "\n",
    "1. Agent는 $s$에서 $d$로 가는 한 경로를 선택한다.\n",
    "1. Environment는 그 경로에 대응하는 edge들 각각의 확률분포에서 소요시간을 생성해 outcome을 반환한다.\n",
    "1. Agent는 edge별 소요시간을 바탕으로 edge별 소요시간 기대값에 대한 믿음을 업데이트한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-petersburg",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-perry",
   "metadata": {},
   "source": [
    "앞에서 구현한 `BinaryBridge` 클래스를 바탕으로 Environment를 구현할 수 있다. 먼저 agent의 action에 대한 outcome을 반환하는 method가 필요하다.\n",
    "- `generate_outcome` : 생성된 Binary Bridge의 경로에 포함된 edge들로부터 소요시간을 생성하는 method\n",
    "\n",
    "또한 Agent들도 $t$시점까지의 theta에 대한 믿음을 저장하고 이를 기반으로 $t+1$시점의 action을 결정할 목적으로(즉, exploit을 할 때), Environment에 정의된 형태의 Binary Bridge를 개인적으로 정의한다. Agent가 exploit중에 action을 결정하는 과정은 $t$시점에 각 edge의 모수 theta에 대한 정보를 업데이트하고, 로 이루어져 있다. 따라서 Environment에 이런 method들이 필요하다.\n",
    "- `overwrite_edge_length` : \n",
    "- `get_shortest_path` : bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "colored-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(BinaryBridge):\n",
    "    \n",
    "    def generate_outcome(self, action, sig2_tilde):\n",
    "        \"\"\"\n",
    "        m에서 n으로 가는 edge에 대응하는 로그정규분포로부터 소요시간 y를 생성해 (m):{(n):y} dictionary 형태로 outcome을 반환\n",
    "        \"\"\"\n",
    "        elapsed_times = defaultdict(dict)\n",
    "        for visiting, destination in zip(action, action[1:]): # edge마다\n",
    "            theta = self.graph[visiting][destination]\n",
    "            parameter_lognorm = np.log(theta) - sig2_tilde / 2\n",
    "            elapsed_time = np.exp(np.random.normal(parameter_lognorm, sig2_tilde)) # 소요시간(y) 생성\n",
    "            elapsed_times[visiting][destination] = elapsed_time\n",
    "\n",
    "        return elapsed_times\n",
    "    \n",
    "    def overwrite_edge_length(self, edge_lengths):\n",
    "        \"\"\"\n",
    "        edge에 대응하는 theta에 대한 agent의 업데이트된 믿음을 덮어씌움\n",
    "        \"\"\"\n",
    "        for start_node in edge_lengths:\n",
    "            for end_node in edge_lengths[start_node]:\n",
    "                self.graph[start_node][end_node] = edge_lengths[start_node][end_node]\n",
    "                \n",
    "    def get_shortest_path(self):\n",
    "        \"\"\"\n",
    "        덮어씌워진 theta로 이루어진 새로운 graph로부터 최단경로를 찾아내 반환\n",
    "        \"\"\"\n",
    "        self._apply_dijkstra()\n",
    "        return self.shortest_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-denmark",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "threaded-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedy:\n",
    "    \n",
    "    def __init__(self, n_stages, mu0, sig02, epsilon=0.0, sig2_tilde=1.):\n",
    "        \"\"\"\n",
    "        theta에 대한 agent의 믿음의 정보를 담고 \n",
    "        \"\"\"\n",
    "        assert (n_stages % 2 == 0), 'number of stages has to be even'\n",
    "        self.n = n_stages\n",
    "        self.mu0 = mu0\n",
    "        self.sig02 = sig02\n",
    "        self.sig2_tilde = sig2_tilde\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.internal_env = Environment(n_stages, mu0, sig02)\n",
    "        self.posterior_params = copy.deepcopy(self.internal_env.graph)\n",
    "        for visiting in self.posterior_params:\n",
    "            for destination in self.posterior_params[visiting]:\n",
    "                self.posterior_params[visiting][destination] = (mu0, sig02)\n",
    "    \n",
    "    def update_parameters(self, action, reward):\n",
    "        \n",
    "        for visiting in reward:\n",
    "            for destination in reward[visiting]:\n",
    "                elapse_time = reward[visiting][destination]\n",
    "                previous_mean, previous_var = self.posterior_params[visiting][destination]\n",
    "                \n",
    "                precision_theta = 1. / previous_var\n",
    "                precision_noise = 1. / self.sig2_tilde\n",
    "                updated_var = 1. / (precision_theta + precision_noise)\n",
    "                \n",
    "                updated_mean = precision_theta * previous_mean + precision_noise * (np.log(elapse_time) + self.sig2_tilde / 2)\n",
    "                updated_mean = updated_mean / (precision_theta + precision_noise)\n",
    "                \n",
    "                self.posterior_params[visiting][destination] = (updated_mean, updated_var)\n",
    "        \n",
    "    def _posterior_mean(self):\n",
    "        posterior_means = copy.deepcopy(self.posterior_params)\n",
    "        for visiting in self.posterior_params:\n",
    "            for destination in self.posterior_params[visiting]:\n",
    "                mean, var = self.posterior_params[visiting][destination]\n",
    "                posterior_means[visiting][destination] = np.exp(mean + var / 2)\n",
    "        \n",
    "        return posterior_means\n",
    "    \n",
    "    def _explore(self):\n",
    "        path = []\n",
    "        start_node = (0,0)\n",
    "        while True:\n",
    "            path += [start_node]\n",
    "            if start_node == (self.n, 0):\n",
    "                break\n",
    "            start_node = random.choice(list(self.internal_env.graph[start_node].keys()))\n",
    "        return path\n",
    "    \n",
    "    def _exploit(self):\n",
    "        posterior_means = self._posterior_mean()\n",
    "        self.internal_env.overwrite_edge_length(posterior_means)\n",
    "        return self.internal_env.get_shortest_path()\n",
    "    \n",
    "    def pick_action(self):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            path = self._explore()\n",
    "        else:\n",
    "            path = self._exploit()\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "violent-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thompson(EpsilonGreedy):\n",
    "    \n",
    "    def _posterior_sample(self):\n",
    "        posterior_samples = copy.deepcopy(self.posterior_params)\n",
    "        for visiting in self.posterior_params:\n",
    "            for destination in self.posterior_params[visiting]:\n",
    "                mean, var = self.posterior_params[visiting][destination]\n",
    "                posterior_samples[visiting][destination] = np.exp(np.random.normal(mean, var))\n",
    "        return posterior_samples\n",
    "        \n",
    "    def pick_action(self):\n",
    "        posterior_samples = self._posterior_sample()\n",
    "        self.internal_env.overwrite_edge_length(posterior_samples)\n",
    "        return self.internal_env.get_shortest_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-louisiana",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "matched-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(response, aggregate=False):\n",
    "    \"\"\"\n",
    "    environment로부터의 response가 실현된 소요시간이라서 사실 reward_function 없이 바로 response를 사용해도 되지만, 소요된 총 시간을 구하는 \n",
    "    \"\"\"\n",
    "    if aggregate:\n",
    "        reward = 0\n",
    "        for visiting in response:\n",
    "            for destination in response[visiting]:\n",
    "                reward += response[visiting][destination]\n",
    "    else:\n",
    "        reward = response\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "familiar-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "\n",
    "    def __init__(self, agent, environment, n_steps, exp_id):\n",
    "        \"\"\"\n",
    "        agent       : predefined instance of Greedy or Thompson class\n",
    "        environment : predefined instance of Environment class\n",
    "        n_steps     : number of steps in current experiment\n",
    "        exp_id      : id of current experiment\n",
    "        \"\"\"\n",
    "        self.agent = agent\n",
    "        self.environment = environment\n",
    "        self.optimal_reward = -environment.minimum_distance\n",
    "        self.n_steps = n_steps\n",
    "        self.exp_id = exp_id\n",
    "        self.result = []\n",
    "        self.data_dict = {}\n",
    "\n",
    "    def _step(self, step_index):\n",
    "        # pick action -> generate outcome -> observe reward of the action -> update belief accordingly\n",
    "        action = self.agent.pick_action()\n",
    "        response = self.environment.generate_outcome(action, self.agent.sig2_tilde)\n",
    "        self.agent.update_parameters(action, reward_function(response))\n",
    "\n",
    "        # calculate regret of current action\n",
    "        expected_reward = 0\n",
    "        for visiting, destination in zip(action, action[1:]):\n",
    "            expected_reward -= self.environment.graph[visiting][destination]\n",
    "        regret = self.optimal_reward - expected_reward\n",
    "\n",
    "        # Leave log\n",
    "        self.cum_regret += regret\n",
    "        self.data_dict = {'step': (step_index + 1), \n",
    "                          'regret': regret, \n",
    "                          'total_dist': reward_function(response, True), \n",
    "                          'action': action, \n",
    "                          'experiment_id':self.exp_id}\n",
    "        self.result.append(self.data_dict)\n",
    "    \n",
    "    def run(self):\n",
    "        self.cum_regret = 0\n",
    "        for t in range(self.n_steps):\n",
    "            self._step(t)\n",
    "        self.result = pd.DataFrame(self.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opening-fantasy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "n_stages = 20\n",
    "mu0 = -0.5\n",
    "sig02 = 1\n",
    "\n",
    "n_steps = 500\n",
    "n_experiment = 500\n",
    "environment = Environment(n_stages, mu0, sig02)\n",
    "agent_types = ['greedy-0.0', 'greedy-0.01', 'greedy-0.05', 'greedy-0.1', 'ts']\n",
    "\n",
    "for exp_id in range(1, n_experiment+1):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(str(exp_id))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    np.random.seed(exp_id)\n",
    "    for agent_type in agent_types:\n",
    "        if agent_type[:6] == 'greedy':\n",
    "            agent = EpsilonGreedy(n_stages, mu0, sig02, epsilon=float(agent_type.split('-')[1]))\n",
    "        else:\n",
    "            agent = Thompson(n_stages, mu0, sig02)\n",
    "        experiment = Experiment(agent, environment, n_steps, exp_id)\n",
    "        experiment.run()\n",
    "        experiment.result.insert(experiment.result.shape[1], 'agent', agent_type)\n",
    "        results.append(experiment.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-verification",
   "metadata": {},
   "source": [
    "# Regret plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bibliographic-conversion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_concat = pd.concat(results)\n",
    "plt_df = df_concat.groupby(['agent', 'step']).agg({'regret':np.mean}).reset_index()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for agent_type in agent_types:\n",
    "    data = plt_df.loc[plt_df['agent'] == agent_type]\n",
    "    ax.plot(data['step'], data['regret'], label=agent_type)\n",
    "\n",
    "ax.set_xlabel('step')\n",
    "ax.set_ylabel('regret')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-judgment",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-russell",
   "metadata": {},
   "source": [
    "## 로그정규분포의 확률밀도함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-therapist",
   "metadata": {},
   "source": [
    "로그정규분포의 확률밀도함수를 도출하는 것은 $X\\sim N(\\mu,\\sigma^2)$일 때 $Y=\\text{exp}(X)$의 확률밀도함수를 도출하는 것이다. $f(x)=\\text{exp}(x)$가 단조증가함수이므로 아래와 같은 전개가 성립한다.\n",
    "$$\n",
    "P(Y\\leq y)=P(\\text{exp}(X)\\leq y)=P(X\\leq\\ln y)=F_X(\\ln y)\n",
    "$$\n",
    "\n",
    "누적분포함수와 확률밀도함수와의 관계를 이용해 아래와 같은 결론을 얻는다.\n",
    "$$\n",
    "p_Y(y)=\\frac{\\mathrm{d}}{\\mathrm{d}y}P(Y\\leq y)=\\frac{\\mathrm{d}}{\\mathrm{d}y}F_X(\\ln y)=\\frac{\\mathrm{d}x}{\\mathrm{d}y}\\frac{\\mathrm{d}}{\\mathrm{d}x}F_X(\\ln y)=\\frac{1}{y}f_X(\\ln y)\n",
    "$$\n",
    "\n",
    "따라서, $X\\sim N(\\mu,\\sigma^2)$일 때, $Y=\\text{exp}(X)$의 확률밀도함수는 아래와 같다.\n",
    "$$\n",
    "\\therefore p_Y(y)=\\frac{1}{y\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\left(-\\frac{(\\ln y-\\mu)^2}{2\\sigma^2}\\right),\\;\\;y>0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-person",
   "metadata": {},
   "source": [
    "## 로그정규분포의 기대값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-registration",
   "metadata": {},
   "source": [
    "위와 같은 확률밀도함수를 갖는 확률변수 $Y$의 평균을 계산해본다. 참고로 $X=\\ln Y$라고 하면 $\\frac{\\mathrm{d}y}{\\mathrm{d}x}=\\text{exp}(x)$이다(즉, $\\mathrm{d}y=\\text{exp}(x)\\mathrm{d}x$)\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[Y]=\\int_0^\\infty\\frac{y}{y\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\left(-\\frac{(\\ln y-\\mu)^2}{2\\sigma^2}\\right)\\mathrm{d}y=\\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}+x\\right)\\mathrm{d}x\n",
    "$$\n",
    "\n",
    "지수부 안을 정리하고, 평균과 분산이 각각 $(\\mu-\\sigma^2, \\sigma^2)$인 정규분포의 성질을 활용하면 아래와 같은 결론을 얻는다.\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[Y]=\\text{exp}\\left(\\mu+\\frac{\\sigma^2}{2}\\right)\\int_{-\\infty}^\\infty\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\left(-\\frac{(x-\\mu+\\sigma^2)^2}{2\\sigma^2}\\right)\\mathrm{d}x=\\text{exp}\\left(\\mu+\\frac{\\sigma^2}{2}\\right)\n",
    "$$\n",
    "\n",
    "이를 통해, 위 예시에서와 같이 평균과 분산이 각각 $(\\ln\\theta-\\frac{\\widetilde{\\sigma}^2}{2}, \\widetilde{\\sigma}^2)$인 정규분포로부터 로그 정규분포를 도출하면 그 로그 정규분포의 평균은 $\\text{exp}\\left(\\ln\\theta-\\frac{\\widetilde{\\sigma}^2}{2}+\\frac{\\widetilde{\\sigma}^2}{2}\\right)=\\theta$가 됨을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-sussex",
   "metadata": {},
   "source": [
    "## $\\theta$에 대한 믿음 업데이트하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-sunset",
   "metadata": {},
   "source": [
    "$t$번째 step에서 노드 $m$에서 노드 $n$으로 향하는 edge를 통과하는 데 걸린 시간이 $y_{m,n,t}$로 측정되었을 때, 이 값을 바탕으로 이 edge를 통과하는 데 걸리는 시간의 기대값인 $\\theta_{m,n}$에 대한 믿음을 업데이트할 수 있다. 즉, 위에서 정의한 $\\theta_{m,n}$와 $y_{m,n,t}|\\theta_{m,n}$의 분포를 바탕으로 $\\theta_{m,n}|y_{m,n,t}$의 분포를 도출한다(편의상 아랫첨자는 생략한다). 먼저, 베이즈 정리에 따라,\n",
    "\n",
    "$$\n",
    "p(\\theta|y)\\propto p(y|\\theta)p(\\theta)\\equiv\\ln p(\\theta|y)\\propto \\ln p(y|\\theta) + \\ln p(\\theta)\n",
    "$$\n",
    "\n",
    "인데, 위에서 정의한 바에 따르면\n",
    "\n",
    "$$\n",
    "\\ln p(y|\\theta)=-\\ln y-\\frac{1}{2}\\ln 2\\pi - \\frac{1}{2}\\ln\\widetilde{\\sigma}^2-\\frac{(\\ln y-\\ln\\theta+\\frac{\\widetilde{\\sigma}^2}{2})^2}{2\\widetilde{\\sigma}^2},\\;\\;\\ln p(\\theta)=-\\ln\\theta-\\frac{1}{2}\\ln 2\\pi-\\frac{1}{2}\\ln\\sigma^2_0-\\frac{(\\ln\\theta-\\mu_0)^2}{2\\sigma^2_0}\n",
    "$$\n",
    "\n",
    "이므로, $\\ln p(y|\\theta) + \\ln p(\\theta)$를 $\\theta$에 대해 정리해서 아래와 같은 결론을 얻는다.\n",
    "\n",
    "$$\n",
    "\\ln p(\\theta|y)\\propto -\\ln\\theta-\\frac{(\\ln\\theta-\\mu_0)^2}{2\\sigma^2_0}-\\frac{\\left(\\ln y-\\ln\\theta+\\frac{\\widetilde{\\sigma}^2}{2}\\right)^2}{2\\widetilde{\\sigma}^2}\\;\\;\\cdots\\;\\;(1)\n",
    "$$\n",
    "\n",
    "이를 로그정규분포의 커널 형태에 맞게 정리할 수 있다. 즉,\n",
    "\n",
    "$$\n",
    "(1) \\propto -\\ln\\theta-\\left\\{\\frac{\\{(\\ln\\theta)^2-2\\mu_0\\ln\\theta+\\mu^2_0\\}}{2\\sigma^2_0}+\\frac{(\\ln\\theta)^2-2\\left(\\ln y+\\frac{\\widetilde{\\sigma}^2}{2}\\right)\\ln\\theta+\\left(\\ln y+\\frac{\\widetilde{\\sigma}^2}{2}\\right)^2}{2\\widetilde{\\sigma}^2}\\right\\}\\;\\;\\cdots\\;\\;(2)\n",
    "$$\n",
    "\n",
    "(2)를 $\\theta$에 대해 더 정리하면,\n",
    "\n",
    "$$\n",
    "(2)\\propto-\\ln\\theta-\\left\\{\\frac{1}{2}\\left(\\frac{1}{\\sigma^2_0}+\\frac{1}{\\widetilde{\\sigma}^2}\\right)(\\ln\\theta)^2-\\left(\\frac{\\mu_0}{\\sigma^2_0}+\\frac{\\ln y}{\\widetilde{\\sigma}^2}+\\frac{1}{2}\\right)\\ln\\theta\\right\\}\\propto-\\ln\\theta-\\frac{\\left\\{\\ln\\theta-\\frac{\\left(\\frac{\\mu_0}{\\sigma^2_0}+\\frac{\\ln y}{\\widetilde{\\sigma}^2}+\\frac{1}{2}\\right)}{\\left(\\frac{1}{\\sigma^2_0}+\\frac{1}{\\widetilde{\\sigma}^2}\\right)}\\right\\}^2}{2\\left(1/\\left(\\frac{1}{\\sigma^2_0}+\\frac{1}{\\widetilde{\\sigma}^2}\\right)\\right)}\n",
    "$$\n",
    "\n",
    "이므로, 아래와 같은 결론을 얻는다.\n",
    "\n",
    "$$\n",
    "\\theta|y\\sim LN\\left(\\frac{\\left(\\frac{\\mu_0}{\\sigma^2_0}+\\frac{\\ln y}{\\widetilde{\\sigma}^2}+\\frac{1}{2}\\right)}{\\left(\\frac{1}{\\sigma^2_0}+\\frac{1}{\\widetilde{\\sigma}^2}\\right)},\\frac{1}{\\left(\\frac{1}{\\sigma^2_0}+\\frac{1}{\\widetilde{\\sigma}^2}\\right)}\\right)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
